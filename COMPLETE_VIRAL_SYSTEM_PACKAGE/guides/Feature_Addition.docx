**üé¨ Viral YouTube Content Generation System**

I\'ll build a complete multi-gatekeeper system specializing in viral
script writing and visual scene architecture. This will be a
production-ready implementation with detailed explanations for every
component.

**üìã System Architecture Overview**

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

‚îÇ SUPERVISOR ORCHESTRATOR (Entry Point) ‚îÇ

‚îÇ Routes to appropriate gatekeeper teams ‚îÇ

‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÇ

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

‚îÇ ‚îÇ ‚îÇ

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

‚îÇ RESEARCH ‚îÇ ‚îÇ VIRAL ‚îÇ ‚îÇ CONTENT ‚îÇ

‚îÇ GATEKEEPER ‚îÇ‚óÑ‚îÄ‚î§ ANALYST ‚îÇ‚óÑ‚îÄ‚î§ SYNTHESIS ‚îÇ

‚îÇ ‚îÇ ‚îÇ GATEKEEPER ‚îÇ ‚îÇ GATEKEEPER ‚îÇ

‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÇ

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

‚îÇ ‚îÇ ‚îÇ

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

‚îÇ SCRIPT WRITER ‚îÇ ‚îÇ VISUAL SCENE ‚îÇ ‚îÇ CONTEXT ‚îÇ

‚îÇ SUBAGENT ‚îÇ ‚îÇ ARCHITECT ‚îÇ ‚îÇ RETRIEVAL ‚îÇ

‚îÇ ‚îÇ ‚îÇ SUBAGENT ‚îÇ ‚îÇ SUBAGENT ‚îÇ

‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

**üöÄ Phase 1: Core Setup and State Management**

**Step 1: Project Setup**

\# Create project directory

mkdir viral-youtube-system

cd viral-youtube-system

\# Initialize Python virtual environment

python3 -m venv venv

\# Activate virtual environment

\# On macOS/Linux:

source venv/bin/activate

\# On Windows:

\# venv\\Scripts\\activate

\# Install dependencies

pip install langchain langgraph anthropic python-dotenv pydantic
chromadb openai tiktoken

**Step 2: Project Structure**

viral-youtube-system/

‚îú‚îÄ‚îÄ agents/

‚îÇ ‚îú‚îÄ‚îÄ gatekeepers/

‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ \_\_init\_\_.py

‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ content_synthesis_gatekeeper.py

‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ research_gatekeeper.py

‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ viral_analyst_gatekeeper.py

‚îÇ ‚îú‚îÄ‚îÄ subagents/

‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ \_\_init\_\_.py

‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ script_writer_subagent.py

‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ visual_scene_architect.py

‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ context_retrieval_subagent.py

‚îÇ ‚îî‚îÄ‚îÄ base_agent.py

‚îú‚îÄ‚îÄ workflows/

‚îÇ ‚îú‚îÄ‚îÄ \_\_init\_\_.py

‚îÇ ‚îî‚îÄ‚îÄ content_generation_workflow.py

‚îú‚îÄ‚îÄ models/

‚îÇ ‚îú‚îÄ‚îÄ \_\_init\_\_.py

‚îÇ ‚îú‚îÄ‚îÄ state.py

‚îÇ ‚îî‚îÄ‚îÄ schemas.py

‚îú‚îÄ‚îÄ tools/

‚îÇ ‚îú‚îÄ‚îÄ \_\_init\_\_.py

‚îÇ ‚îî‚îÄ‚îÄ vector_store.py

‚îú‚îÄ‚îÄ config/

‚îÇ ‚îú‚îÄ‚îÄ \_\_init\_\_.py

‚îÇ ‚îî‚îÄ‚îÄ settings.py

‚îú‚îÄ‚îÄ .env

‚îú‚îÄ‚îÄ requirements.txt

‚îî‚îÄ‚îÄ main.py

**Step 3: Configuration Setup**

**Create .env file:**

\# .env

ANTHROPIC_API_KEY=your_anthropic_api_key_here

OPENAI_API_KEY=your_openai_api_key_here \# For embeddings

**Create config/settings.py:**

\# config/settings.py

\"\"\"

Configuration settings for the viral YouTube content generation system.

This file centralizes all configuration values so they can be easily
modified.

\"\"\"

import os

from dotenv import load_dotenv \# Library to load environment variables
from .env file

\# Load environment variables from .env file

\# This keeps sensitive data like API keys out of code

load_dotenv()

class Settings:

\"\"\"

Settings class to store all configuration values.

Using a class makes it easy to access settings anywhere in the
application.

\"\"\"

\# API Keys - pulled from environment variables for security

ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")

OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")

\# Model Configuration

\# Using Sonnet 4.5 for gatekeepers (complex reasoning)

GATEKEEPER_MODEL = \"claude-sonnet-4-20250514\"

\# Using Haiku for subagents (faster, cheaper for specific tasks)

SUBAGENT_MODEL = \"claude-haiku-4-5-20250514\"

\# Token limits to control costs

GATEKEEPER_MAX_TOKENS = 4000 \# Gatekeepers can generate longer
responses

SUBAGENT_MAX_TOKENS = 2000 \# Subagents are more focused

\# Temperature controls creativity

\# 0 = deterministic (same input = same output)

\# 1 = creative (same input = varied outputs)

GATEKEEPER_TEMPERATURE = 0.3 \# Moderate creativity for planning

SUBAGENT_TEMPERATURE = 0.7 \# Higher creativity for content generation

\# Workflow Configuration

MAX_ITERATIONS = 3 \# Maximum refinement loops to prevent infinite loops

CONSENSUS_THRESHOLD = 0.75 \# 75% agreement required between gatekeepers

\# Vector Store Configuration (for context retrieval)

VECTOR_STORE_PATH = \"./chroma_db\" \# Where to store embeddings locally

CHUNK_SIZE = 500 \# Text chunk size for embeddings (500 tokens)

CHUNK_OVERLAP = 50 \# Overlap between chunks (10% of chunk size)

\# Script Configuration

TARGET_SCRIPT_LENGTH = 5000 \# Words for 30-minute video (\~150
words/min)

MIN_SCENES = 15 \# Minimum number of scenes for visual variety

MAX_SCENES = 30 \# Maximum scenes to maintain coherence

\# Create a singleton instance for easy access throughout the app

settings = Settings()

**Step 4: State Management**

**Create models/state.py:**

\# models/state.py

\"\"\"

State schema defines the data structure that flows through the workflow.

Think of this as a shared document that all agents can read and write
to.

\"\"\"

from typing import TypedDict, Annotated, List, Dict, Optional

from langgraph.graph.message import add_messages

from langchain_core.messages import BaseMessage

class ContentGenerationState(TypedDict):

\"\"\"

Main state schema for the content generation workflow.

TypedDict ensures type safety - Python will warn if we use wrong types.

This prevents bugs and makes the code more maintainable.

\"\"\"

\# ============ MESSAGE HISTORY ============

\# Annotated\[type, reducer_function\] tells LangGraph HOW to update
this field

\# add_messages is a special reducer that APPENDS new messages instead
of replacing

messages: Annotated\[List\[BaseMessage\], add_messages\]

\# ============ INPUT DATA ============

topic: str \# Main topic for the video (e.g., \"The Mystery of Black
Holes\")

target_audience: str \# Who is this for? (e.g., \"Science enthusiasts,
18-35\")

video_style: str \# Style preference (e.g., \"Documentary\",
\"Educational\", \"Entertainment\")

duration_minutes: int \# Target duration (default: 30 minutes)

\# ============ RESEARCH GATEKEEPER OUTPUTS ============

research_findings: Dict\[str, any\] \# Research data collected

\"\"\"

Example structure:

{

\"sources\": \[\"source1\", \"source2\"\],

\"key_facts\": \[\"fact1\", \"fact2\"\],

\"interesting_angles\": \[\"angle1\", \"angle2\"\],

\"viral_examples\": \[{\"video_id\": \"abc\", \"views\": 1000000}\]

}

\"\"\"

research_confidence: float \# 0.0-1.0 confidence in research quality

\# ============ VIRAL ANALYST GATEKEEPER OUTPUTS ============

viral_analysis: Dict\[str, any\] \# Viral pattern analysis

\"\"\"

Example structure:

{

\"viral_hooks\": \[\"hook1\", \"hook2\"\],

\"engagement_patterns\": \[\"pattern1\", \"pattern2\"\],

\"psychological_triggers\": \[\"curiosity\", \"surprise\"\],

\"recommended_structure\": \"3-act structure with cliff hangers\"

}

\"\"\"

viral_score: float \# 0.0-1.0 predicted virality score

\# ============ CONTEXT RETRIEVAL ============

retrieved_context: List\[Dict\] \# Relevant context from vector store

\"\"\"

Example structure:

\[

{\"content\": \"text chunk\", \"score\": 0.95, \"source\": \"doc1\"},

{\"content\": \"text chunk\", \"score\": 0.89, \"source\": \"doc2\"}

\]

\"\"\"

\# ============ SCRIPT WRITER SUBAGENT OUTPUTS ============

script_draft: str \# Full script text

script_metadata: Dict\[str, any\] \# Script analysis

\"\"\"

Example structure:

{

\"word_count\": 5000,

\"estimated_duration\": \"30 minutes\",

\"readability_score\": 8.5,

\"hook_strength\": 9.0,

\"sections\": \[

{\"title\": \"Introduction\", \"duration\": \"3 min\"},

{\"title\": \"Main Content\", \"duration\": \"24 min\"}

\]

}

\"\"\"

\# ============ VISUAL SCENE ARCHITECT OUTPUTS ============

scene_outline: List\[Dict\] \# Scene-by-scene breakdown

\"\"\"

Example structure:

\[

{

\"scene_number\": 1,

\"timecode\": \"00:00-00:30\",

\"script_segment\": \"text for this scene\",

\"visual_description\": \"Wide shot of cosmos\",

\"b_roll_suggestions\": \[\"Hubble images\", \"Space animation\"\],

\"camera_direction\": \"Slow zoom in\",

\"mood\": \"Mysterious, awe-inspiring\",

\"music_suggestion\": \"Ambient, ethereal\"

}

\]

\"\"\"

visual_coherence_score: float \# 0.0-1.0 visual flow quality

\# ============ CONSENSUS AND VALIDATION ============

gatekeeper_consensus: Dict\[str, any\] \# Agreement between gatekeepers

\"\"\"

Example structure:

{

\"agreement_score\": 0.85,

\"disputed_points\": \[\"pacing in act 2\"\],

\"unanimous_approvals\": \[\"hook strength\", \"visual variety\"\],

\"recommendations\": \[\"add more humor in middle section\"\]

}

\"\"\"

\# ============ ITERATION CONTROL ============

iteration_count: int \# How many refinement loops completed

refinement_feedback: List\[str\] \# Feedback from each iteration

quality_score: float \# 0.0-1.0 overall quality assessment

ready_for_production: bool \# Whether content is final

\# ============ WORKFLOW ROUTING ============

next_step: str \# Which agent/gatekeeper should execute next

\"\"\"

Possible values:

\- \"research_gatekeeper\"

\- \"viral_analyst_gatekeeper\"

\- \"content_synthesis_gatekeeper\"

\- \"script_writer_subagent\"

\- \"visual_architect_subagent\"

\- \"context_retrieval\"

\- \"consensus_validation\"

\- \"refinement_loop\"

\- \"END\"

\"\"\"

\# ============ ERROR HANDLING ============

errors: List\[str\] \# Any errors encountered during workflow

warnings: List\[str\] \# Non-critical issues to address

\# ============ CUSTOM REDUCERS ============

def merge_dicts(existing: dict, new: dict) -\> dict:

\"\"\"

Merge two dictionaries, with new values taking precedence.

This is useful when multiple agents update the same dictionary field.

Without this, the second agent would completely replace the first
agent\'s data.

With this, both agents\' data is preserved.

Args:

existing: Current dictionary value

new: New dictionary to merge in

Returns:

Merged dictionary

Example:

existing = {\"score\": 5, \"type\": \"video\"}

new = {\"score\": 8, \"author\": \"Kane\"}

result = {\"score\": 8, \"type\": \"video\", \"author\": \"Kane\"}

\"\"\"

return {\*\*existing, \*\*new} \# \*\* unpacks dictionaries

def append_to_list(existing: list, new: list) -\> list:

\"\"\"

Append new items to existing list without duplicates.

Args:

existing: Current list

new: Items to append

Returns:

Combined list without duplicates

\"\"\"

\# Convert to set to remove duplicates, then back to list

combined = existing + new

return list(dict.fromkeys(combined)) \# Preserves order while removing
dupes

def keep_max(existing: float, new: float) -\> float:

\"\"\"

Keep the maximum value between existing and new.

Useful for scores where we want to track the best result.

Args:

existing: Current value

new: New value

Returns:

Maximum of the two values

\"\"\"

return max(existing, new)

**ü§ñ Phase 2: Base Agent Class**

**Create agents/base_agent.py:**

\# agents/base_agent.py

\"\"\"

Base agent class that all gatekeepers and subagents inherit from.

This provides common functionality to avoid code duplication.

\"\"\"

from langchain_anthropic import ChatAnthropic

from langchain_core.messages import SystemMessage, HumanMessage

from typing import Dict, List, Optional

from abc import ABC, abstractmethod

import json

from config.settings import settings

class BaseAgent(ABC):

\"\"\"

Abstract base class for all agents in the system.

ABC = Abstract Base Class

This means you can\'t create a BaseAgent directly -

you must create a subclass that implements the required methods.

This ensures all agents follow the same structure.

\"\"\"

def \_\_init\_\_(

self,

name: str,

model_name: str,

temperature: float,

max_tokens: int,

role_description: str

):

\"\"\"

Initialize base agent with Claude API client.

Args:

name: Agent\'s display name (e.g., \"Script Writer Subagent\")

model_name: Which Claude model to use (Sonnet vs Haiku)

temperature: Creativity level (0.0-1.0)

max_tokens: Maximum response length

role_description: What this agent does

\"\"\"

\# Store agent configuration

self.name = name

self.role_description = role_description

\# Initialize Claude API client

\# This creates a connection to Anthropic\'s servers

self.llm = ChatAnthropic(

model=model_name,

temperature=temperature,

max_tokens=max_tokens,

api_key=settings.ANTHROPIC_API_KEY \# API key from environment

)

\# Each agent defines their own system prompt

\# This is like giving the agent their job description

self.system_prompt = self.\_get_system_prompt()

\# Track token usage for cost monitoring

self.total_tokens_used = 0

\@abstractmethod

def \_get_system_prompt(self) -\> str:

\"\"\"

Each agent MUST define their specialized system prompt.

\@abstractmethod means:

\- Any class inheriting BaseAgent MUST implement this method

\- You can\'t create an agent without defining what they do

\- Enforces consistent structure across all agents

Returns:

System prompt defining agent\'s role and capabilities

\"\"\"

pass

\@abstractmethod

def execute(self, state: Dict) -\> Dict:

\"\"\"

Main execution method each agent must implement.

This is where the agent does its actual work.

Args:

state: Current workflow state with all data

Returns:

Updated state with agent\'s contributions

\"\"\"

pass

def invoke_llm(

self,

prompt: str,

context: Optional\[Dict\] = None,

use_json: bool = False

) -\> str:

\"\"\"

Common method to call Claude with agent\'s context.

This handles all the repetitive parts of calling the LLM:

\- Adding system prompt

\- Formatting messages

\- Error handling

\- Token tracking

Args:

prompt: What to ask Claude

context: Additional context to include

use_json: Whether to request JSON response

Returns:

Claude\'s response as string

\"\"\"

\# Build message list starting with system prompt

\# System prompt defines the agent\'s personality and role

messages = \[SystemMessage(content=self.system_prompt)\]

\# Add context if provided

\# Context gives Claude additional information to work with

if context:

context_text = self.\_format_context(context)

prompt = f\"CONTEXT:\\n{context_text}\\n\\n{prompt}\"

\# Add JSON instruction if requested

\# This makes Claude return structured data instead of free text

if use_json:

prompt += \"\\n\\nRespond with valid JSON only. No markdown, no
explanations.\"

\# Add the user\'s prompt

messages.append(HumanMessage(content=prompt))

try:

\# Call Claude API

\# invoke() sends the messages and waits for response

response = self.llm.invoke(messages)

\# Track tokens for cost monitoring

\# In production, you\'d get actual token count from API response

self.total_tokens_used += len(prompt.split()) \* 1.3 \# Rough estimate

\# Return the text content of Claude\'s response

return response.content

except Exception as e:

\# If something goes wrong, log it and return error message

error_msg = f\"Error in {self.name}: {str(e)}\"

print(f\"‚ùå {error_msg}\")

return json.dumps({\"error\": error_msg})

def \_format_context(self, context: Dict) -\> str:

\"\"\"

Format context dictionary as readable string for Claude.

Converts:

{\"topic\": \"Black Holes\", \"audience\": \"Science fans\"}

To:

topic: Black Holes

audience: Science fans

Args:

context: Dictionary of context data

Returns:

Formatted string

\"\"\"

lines = \[\]

for key, value in context.items():

\# Handle nested dictionaries and lists nicely

if isinstance(value, (dict, list)):

value = json.dumps(value, indent=2)

lines.append(f\"{key}: {value}\")

return \"\\n\".join(lines)

def extract_json(self, text: str) -\> Dict:

\"\"\"

Extract JSON from Claude\'s response.

Claude sometimes wraps JSON in markdown code blocks like:

\`\`\`json

{\"key\": \"value\"}

\`\`\`

This function handles that and extracts the actual JSON.

Args:

text: Response text that may contain JSON

Returns:

Parsed JSON as dictionary

\"\"\"

\# Remove markdown code blocks if present

text = text.strip()

if text.startswith(\"\`\`\`json\"):

text = text\[7:\] \# Remove \`\`\`json

if text.startswith(\"\`\`\`\"):

text = text\[3:\] \# Remove \`\`\`

if text.endswith(\"\`\`\`\"):

text = text\[:-3\] \# Remove trailing \`\`\`

text = text.strip()

try:

\# Parse JSON string into Python dictionary

return json.loads(text)

except json.JSONDecodeError as e:

\# If JSON is invalid, return error

print(f\"‚ö†Ô∏è Failed to parse JSON from {self.name}: {e}\")

return {\"error\": \"Invalid JSON response\", \"raw_text\": text}

def log(self, message: str, level: str = \"INFO\"):

\"\"\"

Simple logging method for agent actions.

In production, you\'d use Python\'s logging module.

Args:

message: What to log

level: INFO, WARNING, ERROR, SUCCESS

\"\"\"

emoji = {

\"INFO\": \"‚ÑπÔ∏è\",

\"WARNING\": \"‚ö†Ô∏è\",

\"ERROR\": \"‚ùå\",

\"SUCCESS\": \"‚úÖ\"

}

print(f\"{emoji.get(level, \'‚ÑπÔ∏è\')} \[{self.name}\] {message}\")

I\'ll continue with the gatekeepers and subagents implementation in the
next response. Would you like me to proceed with the complete
implementation?
